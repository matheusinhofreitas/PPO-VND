gym_customizedEnv-v0:
  learning_rate: lin_0.001
  #learning_rate_decay:
  gamma: 0.98
  #gamma_decay: 
  #num_optimization_epchs:
  batch_size: 256
  #mini_batch_size:
  clip_range: lin_0.2
  ent_coef: 0.0
  #value_function_coefficient:
  #advatage_coefficient:
  #num_step_per_iteration:
  #experience_buffer_size:
  n_envs: 4
  n_timesteps: 1000 #100000 = !!float 1e5
  policy: MlpPolicy
  n_steps: 100
  gae_lambda: 0.8
  n_epochs: 20

